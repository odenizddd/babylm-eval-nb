{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/odenizddd/babylm-eval-nb/blob/main/BabyLM_Evaluation_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfxV13o02TjF"
      },
      "source": [
        "copy necessary files from huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /\n",
        "\n",
        "!rm -rf /content/evaluation-pipeline-2023\n",
        "!rm -rf /content/elc-bert-replica"
      ],
      "metadata": {
        "id": "q54tboEV1rOi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slJ3LaDE1Q0H",
        "outputId": "63baed29-ae63-4245-8a02-524c4fc9c284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Git LFS initialized.\n",
            "Cloning into 'elc-bert-replica'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (18/18), 50.87 KiB | 4.24 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 592.96 MiB | 122.27 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install git-lfs\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/odenizddd/elc-bert-replica\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRGWKaudsoSu"
      },
      "source": [
        "# Instructions\n",
        "This notebook allows you to load and evaluate a huggingface model on a subset of BLiMP (a linguistic acceptability judgment dataset) and GLUE (a natural language understanding benchmark collection). It is HIGHLY recommended to clone the GitHub repository and evaluate your model in the command-line; this will give you more freedom in the kinds of models you can evaluate. However, Colab provides a GPU that will allow you to load and evaluate smaller models.\n",
        "\n",
        "To use this notebook:\n",
        "\n",
        "1. Start by making a copy of this notebook so that you can make edits and run the code: File > Save a copy in Drive.\n",
        "\n",
        "2. Set Runtime > Change runtime type > Hardware accelerator to GPU if it isn't already.\n",
        "\n",
        "3. Run the setup script to install the required packages for evaluating.\n",
        "\n",
        "4. Upload your model to the colab in the `/content/model_folder/` directory. This folder should include the following files, and probably a couple more depending on the type of model and tokenizer you use:\n",
        "* `config.json`\n",
        "* `pytorch_model.bin`\n",
        "* `tokenizer_config.json`\n",
        "* `vocab.json`\n",
        "\n",
        "  a. To obtain these files given your pre-trained model and your tokenizer, load them using huggingface `transformers` and save them using these commands:\n",
        "```\n",
        "tokenizer.save_pretrained(\"./model_dir\")\n",
        "model.save_pretrained(\"./model_dir\")\n",
        "```\n",
        "  b. Then, upload all the contents of `model_dir` (including any other files not mentioned above) to the `model_folder` folder in this Colab.\n",
        "\n",
        "5. Choose the proper model type in the dropdown in the \"load model and evaluate\" cell. Use \"decoder\" for autoregressive (sometimes called \"causal\") language models, like GPT/OPT; \"encoder\" for masked language models, like BERT/RoBERTa; or \"encoder-decoder\" for text-to-text models, like T5/BART.\n",
        "\n",
        "6. Run the cells below to load and evaluate your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbPFbtYqMREj",
        "outputId": "6a366555-8dd3-453e-f938-026b7f340f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 2,474 kB of archives.\n",
            "After this operation, 2,885 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.5 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.2 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.9 [5,722 B]\n",
            "Fetched 2,474 kB in 1s (1,707 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.9_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.9) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.9) ...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2225k  100 2225k    0     0  8702k      0 --:--:-- --:--:-- --:--:-- 8694k\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.1.1 setuptools-80.8.0 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3.10-venv python3.10-distutils -y\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3.10 get-pip.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk4Epwozk_sf",
        "outputId": "02b99b8f-f4d7-4faa-a09f-1a1554d277e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping lm-eval as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mObtaining file:///content/evaluation-pipeline-2023\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets>=2.0.0 (from lm_eval==0.2.0)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting nltk==3.6 (from lm_eval==0.2.0)\n",
            "  Downloading nltk-3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting openai==0.13.0 (from lm_eval==0.2.0)\n",
            "  Downloading openai-0.13.0.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycountry==20.7.3 (from lm_eval==0.2.0)\n",
            "  Downloading pycountry-20.7.3.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytablewriter==0.58.0 (from lm_eval==0.2.0)\n",
            "  Downloading pytablewriter-0.58.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting rouge-score==0.0.4 (from lm_eval==0.2.0)\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting sacrebleu==1.5.0 (from lm_eval==0.2.0)\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting scikit-learn>=0.24.1 (from lm_eval==0.2.0)\n",
            "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting sqlitedict==1.6.0 (from lm_eval==0.2.0)\n",
            "  Downloading sqlitedict-1.6.0.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==1.13.0 (from lm_eval==0.2.0)\n",
            "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl.metadata (23 kB)\n",
            "Collecting evaluate==0.4.0 (from lm_eval==0.2.0)\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting tqdm-multiprocess==0.0.11 (from lm_eval==0.2.0)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting accelerate@ git+https://github.com/huggingface/accelerate@v0.20.0 (from lm_eval==0.2.0)\n",
            "  Cloning https://github.com/huggingface/accelerate (to revision v0.20.0) to /tmp/pip-install-j2q22t86/accelerate_4f2dfc5b17094f23afa57887ac95a06a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-install-j2q22t86/accelerate_4f2dfc5b17094f23afa57887ac95a06a\n",
            "  Running command git checkout -q a6418cac4f2123d2ad4590cbf5204b9fcb0e3f8f\n",
            "  Resolved https://github.com/huggingface/accelerate to commit a6418cac4f2123d2ad4590cbf5204b9fcb0e3f8f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers==4.26.1 (from lm_eval==0.2.0)\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl.metadata (100 kB)\n",
            "Collecting numpy>=1.17 (from accelerate@ git+https://github.com/huggingface/accelerate@v0.20.0->lm_eval==0.2.0)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting packaging>=20.0 (from accelerate@ git+https://github.com/huggingface/accelerate@v0.20.0->lm_eval==0.2.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting psutil (from accelerate@ git+https://github.com/huggingface/accelerate@v0.20.0->lm_eval==0.2.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pyyaml (from accelerate@ git+https://github.com/huggingface/accelerate@v0.20.0->lm_eval==0.2.0)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting black<=21.12b0 (from lm_eval==0.2.0)\n",
            "  Downloading black-21.12b0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting coverage<=6.2 (from lm_eval==0.2.0)\n",
            "  Downloading coverage-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting mock>=4.0.3 (from lm_eval==0.2.0)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pytest (from lm_eval==0.2.0)\n",
            "  Downloading pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon (from lm_eval==0.2.0)\n",
            "  Cloning https://github.com/bigscience-workshop/promptsource (to revision eval-hackathon) to /tmp/pip-install-j2q22t86/promptsource_15b6068a1ceb455984b3aa0d969a4bb0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/bigscience-workshop/promptsource /tmp/pip-install-j2q22t86/promptsource_15b6068a1ceb455984b3aa0d969a4bb0\n",
            "  Running command git checkout -b eval-hackathon --track origin/eval-hackathon\n",
            "  Switched to a new branch 'eval-hackathon'\n",
            "  Branch 'eval-hackathon' set up to track remote branch 'eval-hackathon' from 'origin'.\n",
            "  Resolved https://github.com/bigscience-workshop/promptsource to commit e3a22e09d0131a6ca6810ad8684c59eab3ede13d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flake8 (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading flake8-7.2.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting isort==5.8.0 (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading isort-5.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting streamlit==0.82 (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading streamlit-0.82.0-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jinja2 (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting plotly (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading plotly-6.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting requests (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pandas (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting py7zr (from promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting dill (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tqdm>=4.62.1 (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting xxhash (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "\u001b[33mWARNING: Package 'nltk' has an invalid Requires-Python: Invalid specifier: '>=3.5.*'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting click (from nltk==3.6->lm_eval==0.2.0)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting joblib (from nltk==3.6->lm_eval==0.2.0)\n",
            "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting regex (from nltk==3.6->lm_eval==0.2.0)\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting pandas-stubs>=1.1.0.11 (from openai==0.13.0->lm_eval==0.2.0)\n",
            "  Downloading pandas_stubs-2.2.3.250308-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting openpyxl>=3.0.7 (from openai==0.13.0->lm_eval==0.2.0)\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter==0.58.0->lm_eval==0.2.0) (80.8.0)\n",
            "Collecting DataProperty<2,>=0.50.0 (from pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting msgfy<1,>=0.1.0 (from pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading msgfy-0.2.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0 (from pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading pathvalidate-2.5.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tabledata<2,>=1.1.3 (from pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.1.1 (from typepy[datetime]<2,>=1.1.1->pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting absl-py (from rouge-score==0.0.4->lm_eval==0.2.0)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score==0.0.4->lm_eval==0.2.0) (1.16.0)\n",
            "Collecting portalocker (from sacrebleu==1.5.0->lm_eval==0.2.0)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting altair>=3.2.0 (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting astor (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting base58 (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: blinker in /usr/lib/python3/dist-packages (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0) (1.4)\n",
            "Collecting cachetools>=4.0 (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting click (from nltk==3.6->lm_eval==0.2.0)\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pillow>=6.2.0 (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting protobuf!=3.11,>=3.6.0 (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting pydeck>=0.1.dev5 (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting python-dateutil (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting toml (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting tornado>=5.0 (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading tornado-6.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting tzlocal (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting validators (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting gitpython (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting watchdog (from streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "Collecting typing-extensions (from torch==1.13.0->lm_eval==0.2.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0->lm_eval==0.2.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0->lm_eval==0.2.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0->lm_eval==0.2.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0->lm_eval==0.2.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->lm_eval==0.2.0) (0.45.1)\n",
            "Collecting colorama (from tqdm-multiprocess==0.0.11->lm_eval==0.2.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting filelock (from transformers==4.26.1->lm_eval==0.2.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.1->lm_eval==0.2.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting platformdirs>=2 (from black<=21.12b0->lm_eval==0.2.0)\n",
            "  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tomli<2.0.0,>=0.2.6 (from black<=21.12b0->lm_eval==0.2.0)\n",
            "  Downloading tomli-1.2.3-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting pathspec<1,>=0.9.0 (from black<=21.12b0->lm_eval==0.2.0)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black<=21.12b0->lm_eval==0.2.0)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting urllib3>=1.25.10 (from responses<0.19->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pytz>=2018.9 (from typepy[datetime]<2,>=1.1.1->pytablewriter==0.58.0->lm_eval==0.2.0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jsonschema>=3.0 (from altair>=3.2.0->streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting narwhals>=1.14.2 (from altair>=3.2.0->streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading narwhals-1.40.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->lm_eval==0.2.0)\n",
            "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.0->lm_eval==0.2.0)\n",
            "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading rpds_py-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting et-xmlfile (from openpyxl>=3.0.7->openai==0.13.0->lm_eval==0.2.0)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting types-pytz>=2022.1.1 (from pandas-stubs>=1.1.0.11->openai==0.13.0->lm_eval==0.2.0)\n",
            "  Downloading types_pytz-2025.2.0.20250516-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0) (2.0.1)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn>=0.24.1->lm_eval==0.2.0)\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval==0.2.0)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pycodestyle<2.14.0,>=2.13.0 (from flake8->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pycodestyle-2.13.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting pyflakes<3.4.0,>=3.3.0 (from flake8->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pyflakes-3.3.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->streamlit==0.82->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting texttable (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pyzstd-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading pybcj-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr->promptsource@ git+https://github.com/bigscience-workshop/promptsource@eval-hackathon->lm_eval==0.2.0)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc8 (from pytest->lm_eval==0.2.0)\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting iniconfig (from pytest->lm_eval==0.2.0)\n",
            "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pluggy<2,>=1.5 (from pytest->lm_eval==0.2.0)\n",
            "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "Downloading isort-5.8.0-py3-none-any.whl (103 kB)\n",
            "Downloading nltk-3.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytablewriter-0.58.0-py3-none-any.whl (96 kB)\n",
            "Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "Downloading streamlit-0.82.0-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m145.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-21.12b0-py3-none-any.whl (156 kB)\n",
            "Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "Downloading coverage-6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (215 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "Downloading msgfy-0.2.1-py3-none-any.whl (4.4 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n",
            "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-1.2.3-py3-none-any.whl (12 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
            "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Downloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading narwhals-1.40.0-py3-none-any.whl (357 kB)\n",
            "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas_stubs-2.2.3.250308-py3-none-any.whl (158 kB)\n",
            "Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\n",
            "Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
            "Downloading protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl (320 kB)\n",
            "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rpds_py-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
            "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tornado-6.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading types_pytz-2025.2.0.20250516-py3-none-any.whl (10 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading flake8-7.2.0-py2.py3-none-any.whl (57 kB)\n",
            "Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Downloading pycodestyle-2.13.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading pyflakes-3.3.2-py2.py3-none-any.whl (63 kB)\n",
            "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading plotly-6.1.1-py3-none-any.whl (16.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "Downloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "Downloading pybcj-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "Downloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "Downloading pytest-8.3.5-py3-none-any.whl (343 kB)\n",
            "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
            "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Building wheels for collected packages: accelerate, promptsource, openai, pycountry, sqlitedict\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.20.0-py3-none-any.whl size=227456 sha256=b9654559ec2c20ba251aafcf8a57d101fe1ae6bde671d4d029c8bcccf345ef79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nj7_yhes/wheels/32/c4/92/fda36e0094fb9231eb1907450a612b19f62cf344bc4a28fc0d\n",
            "\u001b[33m  DEPRECATION: Building 'promptsource' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'promptsource'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for promptsource (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promptsource: filename=promptsource-0.2.3-py3-none-any.whl size=566256 sha256=ecc5c115f6f0b132e12ffe0002a2f0c2d6b392f6eeacc70261b2283b9d05fec6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nj7_yhes/wheels/25/55/6c/6988f5fff60fd7a59f5cdafda42b2cf1e2c4d779b6aa531f23\n",
            "\u001b[33m  DEPRECATION: Building 'openai' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'openai'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.13.0-py3-none-any.whl size=46147 sha256=1267d9ce6d13f9526996fd210ce673b014d9a6b037fc7dcbb0b82dc17de1e091\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/85/ff/4f06a400af79be38243b7a07460a44465d4d1b01741792324d\n",
            "\u001b[33m  DEPRECATION: Building 'pycountry' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pycountry'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746934 sha256=30c17f994e750688e0d2d0bb3d81c69184a127e4be43ff6ea9a4332be9bb1e03\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/02/fb/ae3c9bc96046c6ac677a5fca5a6b52519f1c8ba91e6f3a00dd\n",
            "\u001b[33m  DEPRECATION: Building 'sqlitedict' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sqlitedict'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-py3-none-any.whl size=14820 sha256=4cf9b1e2d559ad387b37e7a678cd62ecb81fe3e8a65be37c691d1dae3ba753e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/9e/12/4ec58b73bc9b67a772c219802cd79a2aa26853c35a975a7b62\n",
            "Successfully built accelerate promptsource openai pycountry sqlitedict\n",
            "Installing collected packages: tokenizers, texttable, sqlitedict, pytz, pycountry, brotli, xxhash, watchdog, validators, urllib3, tzlocal, tzdata, typing-extensions, types-pytz, tqdm, tornado, tomli, toml, threadpoolctl, tcolorpy, smmap, rpds-py, regex, pyyaml, python-dateutil, pyppmd, pyflakes, pycryptodomex, pycodestyle, pybcj, pyarrow, psutil, protobuf, propcache, portalocker, pluggy, platformdirs, pillow, pathvalidate, pathspec, packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, narwhals, mypy-extensions, multivolumefile, msgfy, mock, mccabe, joblib, jinja2, isort, iniconfig, inflate64, idna, fsspec, frozenlist, filelock, et-xmlfile, dill, coverage, colorama, click, charset-normalizer, chardet, certifi, cachetools, base58, attrs, async-timeout, astor, aiohappyeyeballs, absl-py, tqdm-multiprocess, scipy, sacrebleu, requests, referencing, pyzstd, pydeck, plotly, pandas-stubs, pandas, openpyxl, nvidia-cudnn-cu11, nltk, multiprocess, multidict, mbstrdecoder, gitdb, flake8, exceptiongroup, black, aiosignal, yarl, typepy, torch, scikit-learn, rouge-score, responses, pytest, py7zr, openai, jsonschema-specifications, huggingface-hub, gitpython, transformers, jsonschema, aiohttp, accelerate, DataProperty, altair, tabledata, streamlit, datasets, pytablewriter, promptsource, evaluate, lm_eval\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m118/121\u001b[0m [promptsource]\u001b[33m  DEPRECATION: Legacy editable install of lm_eval[colab]==0.2.0 from file:///content/evaluation-pipeline-2023 (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[2K  Running setup.py develop for lm_eval\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121/121\u001b[0m [lm_eval]\n",
            "\u001b[1A\u001b[2KSuccessfully installed DataProperty-1.1.0 absl-py-2.2.2 accelerate-0.20.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 altair-5.5.0 astor-0.8.1 async-timeout-5.0.1 attrs-25.3.0 base58-2.1.1 black-21.12b0 brotli-1.1.0 cachetools-5.5.2 certifi-2025.4.26 chardet-5.2.0 charset-normalizer-3.4.2 click-7.1.2 colorama-0.4.6 coverage-6.2 datasets-3.6.0 dill-0.3.8 et-xmlfile-2.0.0 evaluate-0.4.0 exceptiongroup-1.3.0 filelock-3.18.0 flake8-7.2.0 frozenlist-1.6.0 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.44 huggingface-hub-0.31.4 idna-3.10 inflate64-1.0.1 iniconfig-2.1.0 isort-5.8.0 jinja2-3.1.6 joblib-1.5.0 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 lm_eval-0.2.0 mbstrdecoder-1.1.4 mccabe-0.7.0 mock-5.2.0 msgfy-0.2.1 multidict-6.4.4 multiprocess-0.70.16 multivolumefile-0.2.3 mypy-extensions-1.1.0 narwhals-1.40.0 nltk-3.6 numpy-2.2.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 openai-0.13.0 openpyxl-3.1.5 packaging-25.0 pandas-2.2.3 pandas-stubs-2.2.3.250308 pathspec-0.12.1 pathvalidate-2.5.2 pillow-11.2.1 platformdirs-4.3.8 plotly-6.1.1 pluggy-1.6.0 portalocker-3.1.1 promptsource-0.2.3 propcache-0.3.1 protobuf-6.31.0 psutil-7.0.0 py7zr-0.22.0 pyarrow-20.0.0 pybcj-1.0.6 pycodestyle-2.13.0 pycountry-20.7.3 pycryptodomex-3.23.0 pydeck-0.9.1 pyflakes-3.3.2 pyppmd-1.1.1 pytablewriter-0.58.0 pytest-8.3.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 pyzstd-0.17.0 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 responses-0.18.0 rouge-score-0.0.4 rpds-py-0.25.1 sacrebleu-1.5.0 scikit-learn-1.6.1 scipy-1.15.3 smmap-5.0.2 sqlitedict-1.6.0 streamlit-0.82.0 tabledata-1.3.4 tcolorpy-0.1.7 texttable-1.7.0 threadpoolctl-3.6.0 tokenizers-0.13.3 toml-0.10.2 tomli-1.2.3 torch-1.13.0 tornado-6.5 tqdm-4.67.1 tqdm-multiprocess-0.0.11 transformers-4.26.1 typepy-1.3.4 types-pytz-2025.2.0.20250516 typing-extensions-4.13.2 tzdata-2025.2 tzlocal-5.3.1 urllib3-2.4.0 validators-0.35.0 watchdog-6.0.0 xxhash-3.5.0 yarl-1.20.0\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.0+cu113 (from versions: 1.11.0, 1.11.0+cu113, 1.12.0, 1.12.0+cu113, 1.12.1, 1.12.1+cu113, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.0+cu113\u001b[0m\u001b[31m\n",
            "\u001b[0mArchive:  filter_data.zip\n",
            "   creating: filter-data/\n",
            "   creating: filter-data/syllogisms_filtered/\n",
            "   creating: filter-data/syllogisms_filtered/syllogism_problems/\n",
            "  inflating: filter-data/syllogisms_filtered/syllogism_problems/syllogism_problems.json  \n",
            "  inflating: filter-data/syllogisms_filtered/syllogism_problems/LICENSE.txt  \n",
            "  inflating: filter-data/syllogisms_filtered/syllogisms_nonsense.train  \n",
            "   creating: filter-data/glue_filtered/\n",
            "  inflating: filter-data/glue_filtered/boolq.test.json  \n",
            "  inflating: filter-data/glue_filtered/boolq.train.json  \n",
            "  inflating: filter-data/glue_filtered/boolq.validation.json  \n",
            "  inflating: filter-data/glue_filtered/cola.test.json  \n",
            "  inflating: filter-data/glue_filtered/cola.train.json  \n",
            "  inflating: filter-data/glue_filtered/cola.validation.json  \n",
            "  inflating: filter-data/glue_filtered/mnli_mismatched.test.json  \n",
            "  inflating: filter-data/glue_filtered/mnli.test.json  \n",
            "  inflating: filter-data/glue_filtered/mnli.train.json  \n",
            "  inflating: filter-data/glue_filtered/mnli.validation_matched.json  \n",
            "  inflating: filter-data/glue_filtered/mnli.validation_mismatched.json  \n",
            "  inflating: filter-data/glue_filtered/mrpc.test.json  \n",
            "  inflating: filter-data/glue_filtered/mrpc.train.json  \n",
            "  inflating: filter-data/glue_filtered/mrpc.validation.json  \n",
            "  inflating: filter-data/glue_filtered/multirc.test.json  \n",
            "  inflating: filter-data/glue_filtered/multirc.train.json  \n",
            "  inflating: filter-data/glue_filtered/multirc.validation.json  \n",
            "  inflating: filter-data/glue_filtered/qnli.test.json  \n",
            "  inflating: filter-data/glue_filtered/qnli.train.json  \n",
            "  inflating: filter-data/glue_filtered/qnli.validation.json  \n",
            "  inflating: filter-data/glue_filtered/qqp.test.json  \n",
            "  inflating: filter-data/glue_filtered/qqp.train.json  \n",
            "  inflating: filter-data/glue_filtered/qqp.validation.json  \n",
            "  inflating: filter-data/glue_filtered/rte.test.json  \n",
            "  inflating: filter-data/glue_filtered/rte.train.json  \n",
            "  inflating: filter-data/glue_filtered/rte.validation.json  \n",
            "  inflating: filter-data/glue_filtered/sst2.test.json  \n",
            "  inflating: filter-data/glue_filtered/sst2.train.json  \n",
            "  inflating: filter-data/glue_filtered/sst2.validation.json  \n",
            "  inflating: filter-data/glue_filtered/wsc.test.json  \n",
            "  inflating: filter-data/glue_filtered/wsc.train.json  \n",
            "  inflating: filter-data/glue_filtered/wsc.validation.json  \n",
            "   creating: filter-data/blimp_filtered/\n",
            "  inflating: filter-data/blimp_filtered/island_effects.json  \n",
            "  inflating: filter-data/blimp_filtered/anaphor_agreement.json  \n",
            "  inflating: filter-data/blimp_filtered/argument_structure.json  \n",
            "  inflating: filter-data/blimp_filtered/determiner_noun_agreement.json  \n",
            "  inflating: filter-data/blimp_filtered/subject_verb_agreement.json  \n",
            "  inflating: filter-data/blimp_filtered/ellipsis.json  \n",
            "  inflating: filter-data/blimp_filtered/control_raising.json  \n",
            "  inflating: filter-data/blimp_filtered/quantifiers.json  \n",
            "  inflating: filter-data/blimp_filtered/irregular_forms.json  \n",
            "  inflating: filter-data/blimp_filtered/npi_licensing.json  \n",
            "  inflating: filter-data/blimp_filtered/binding.json  \n",
            "  inflating: filter-data/blimp_filtered/filler_gap.json  \n",
            "   creating: filter-data/msgs_filtered/\n",
            "  inflating: filter-data/msgs_filtered/syntactic_category_lexical_content_the.train.json  \n",
            "  inflating: filter-data/msgs_filtered/syntactic_category_control.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/syntactic_category_control.train.json  \n",
            "  inflating: filter-data/msgs_filtered/main_verb_control.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/lexical_content_the_control.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/syntactic_category_relative_position.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/control_raising_relative_token_position.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/main_verb_lexical_content_the.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/main_verb_relative_token_position.train.json  \n",
            "  inflating: filter-data/msgs_filtered/control_raising_control.train.json  \n",
            "  inflating: filter-data/msgs_filtered/syntactic_category_lexical_content_the.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/control_raising_lexical_content_the.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/lexical_content_the_control.train.json  \n",
            "  inflating: filter-data/msgs_filtered/control_raising_control.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/relative_position_control.train.json  \n",
            "  inflating: filter-data/msgs_filtered/main_verb_control.train.json  \n",
            "  inflating: filter-data/msgs_filtered/control_raising_relative_token_position.train.json  \n",
            "  inflating: filter-data/msgs_filtered/control_raising_lexical_content_the.train.json  \n",
            "  inflating: filter-data/msgs_filtered/main_verb_lexical_content_the.train.json  \n",
            "  inflating: filter-data/msgs_filtered/syntactic_category_relative_position.train.json  \n",
            "  inflating: filter-data/msgs_filtered/relative_position_control.validation.json  \n",
            "  inflating: filter-data/msgs_filtered/main_verb_relative_token_position.validation.json  \n",
            "  inflating: filter-data/glue_filtered/mnli.test_matched.json  \n",
            "  inflating: filter-data/glue_filtered/mnli.test_mismatched.json  \n",
            "   creating: filter-data/supplement_filtered/\n",
            "  inflating: filter-data/supplement_filtered/qa_congruence_tricky.json  \n",
            "  inflating: filter-data/supplement_filtered/turn_taking.json  \n",
            "  inflating: filter-data/supplement_filtered/qa_congruence_easy.json  \n",
            "  inflating: filter-data/supplement_filtered/subject_aux_inversion.json  \n",
            "  inflating: filter-data/supplement_filtered/hypernym.json  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#@title Setup script { display-mode: \"form\" }\n",
        "#@markdown Run this cell to install the necessary packages (may take a few minutes).\n",
        "%%shell\n",
        "# Remove previous installation if it exists\n",
        "cd /content\n",
        "mkdir -p model_folder\n",
        "pip uninstall -y lm-eval\n",
        "rm -rf evaluation-pipeline-2023/\n",
        "\n",
        "# Install evaluation-pipeline\n",
        "git clone https://github.com/odenizddd/evaluation-pipeline-2023 &> /dev/null\n",
        "cd evaluation-pipeline-2023/\n",
        "python3.10 -m pip install -e \".[colab]\"\n",
        "# Install other necessary packages\n",
        "python3.10 -m pip install torch==1.13.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "# Unpack dataset\n",
        "unzip filter_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iu0RtSOmFGq"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMHLEFyBM3k2",
        "outputId": "f7cf4f7b-f4d6-4885-c4d8-4f5d394c30b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.2.6)\n"
          ]
        }
      ],
      "source": [
        "!python3.10 -m pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ftRocjmIa4",
        "outputId": "a0bc5cb3-8e9a-4c53-a6a1-7e4670a23880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/evaluation-pipeline-2023\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/content/evaluation-pipeline-2023/babylm_eval.py\", line 48, in <module>\n",
            "    eval_model = lm_eval.get_model(MODEL_TYPE_REMAP[args.model_type],\n",
            "  File \"/content/evaluation-pipeline-2023/lm_eval/models/__init__.py\", line 42, in get_model\n",
            "    return model_api_class(**model_kwargs)\n",
            "  File \"/content/evaluation-pipeline-2023/lm_eval/models/huggingface.py\", line 175, in __init__\n",
            "    self.model = self._create_auto_model(\n",
            "  File \"/content/evaluation-pipeline-2023/lm_eval/models/huggingface.py\", line 208, in _create_auto_model\n",
            "    model = self.AUTO_MODEL_CLASS.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 459, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 2301, in from_pretrained\n",
            "    state_dict = load_state_dict(resolved_archive_file)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 415, in load_state_dict\n",
            "    return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 789, in load\n",
            "    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1131, in _load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 153, in _rebuild_tensor_v2\n",
            "    tensor = _rebuild_tensor(storage, storage_offset, size, stride)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 146, in _rebuild_tensor\n",
            "    t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:146: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)\n",
            "  t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)\n",
            "Some weights of the model checkpoint at /content/elc-bert-replica were not used when initializing LtgBertForMaskedLM: ['args', 'model', 'epoch', 'optimizer', 'grad_scaler', 'global_step', 'scheduler']\n",
            "- This IS expected if you are initializing LtgBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LtgBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LtgBertForMaskedLM were not initialized from the model checkpoint at /content/elc-bert-replica and are newly initialized: ['transformer.layers.5.attention.in_proj_qk.bias', 'transformer.layers.3.prev_layer_weights', 'transformer.layers.11.attention.in_proj_qk.bias', 'transformer.layers.0.mlp.mlp.1.weight', 'transformer.layers.9.attention.in_proj_v.bias', 'transformer.layers.7.mlp.mlp.4.weight', 'transformer.layers.8.attention.in_proj_v.bias', 'transformer.layers.10.prev_layer_weights', 'transformer.layers.7.attention.post_layer_norm.bias', 'transformer.layers.4.attention.position_indices', 'embedding.word_embedding.weight', 'transformer.layers.0.attention.in_proj_qk.weight', 'transformer.layers.10.mlp.mlp.1.weight', 'transformer.layers.6.attention.position_indices', 'transformer.layers.2.attention.out_proj.weight', 'transformer.layers.7.attention.in_proj_v.weight', 'transformer.layers.9.attention.post_layer_norm.bias', 'transformer.layers.11.attention.in_proj_v.weight', 'transformer.layers.9.attention.out_proj.bias', 'transformer.layers.8.attention.in_proj_qk.bias', 'transformer.layers.10.attention.post_layer_norm.bias', 'transformer.layers.11.attention.out_proj.weight', 'transformer.layers.6.attention.out_proj.weight', 'transformer.layers.8.mlp.mlp.1.weight', 'transformer.layers.6.mlp.mlp.4.weight', 'transformer.layers.4.attention.in_proj_v.bias', 'transformer.layers.7.attention.out_proj.weight', 'transformer.layers.3.mlp.mlp.4.weight', 'transformer.layers.4.attention.post_layer_norm.bias', 'transformer.layers.8.attention.in_proj_v.weight', 'transformer.layers.9.mlp.mlp.4.weight', 'transformer.layers.10.attention.out_proj.bias', 'transformer.layers.2.attention.in_proj_qk.bias', 'classifier.nonlinearity.5.weight', 'transformer.layers.0.attention.in_proj_qk.bias', 'transformer.layers.7.prev_layer_weights', 'transformer.layers.3.attention.in_proj_qk.weight', 'transformer.layers.4.attention.in_proj_qk.bias', 'transformer.layers.10.mlp.mlp.4.weight', 'transformer.layers.2.attention.in_proj_v.weight', 'transformer.layers.11.prev_layer_weights', 'transformer.layers.11.attention.in_proj_v.bias', 'transformer.layers.7.attention.in_proj_v.bias', 'transformer.layers.1.attention.post_layer_norm.weight', 'transformer.layers.4.mlp.mlp.1.weight', 'transformer.layers.8.attention.out_proj.weight', 'transformer.layers.9.mlp.mlp.1.weight', 'transformer.layers.5.attention.out_proj.weight', 'embedding.relative_embedding', 'transformer.layers.0.attention.out_proj.bias', 'embedding.relative_layer_norm.weight', 'transformer.layers.10.attention.position_indices', 'transformer.layers.3.attention.post_layer_norm.bias', 'transformer.layers.10.attention.post_layer_norm.weight', 'transformer.layers.10.attention.in_proj_qk.bias', 'transformer.layers.4.attention.out_proj.weight', 'transformer.layers.10.attention.out_proj.weight', 'transformer.layers.5.attention.in_proj_v.weight', 'transformer.layers.0.attention.in_proj_v.weight', 'transformer.layers.1.mlp.mlp.1.weight', 'transformer.layers.8.attention.post_layer_norm.weight', 'transformer.layers.9.attention.out_proj.weight', 'transformer.layers.11.attention.position_indices', 'transformer.layers.5.attention.post_layer_norm.weight', 'transformer.layers.5.attention.position_indices', 'transformer.layers.4.attention.post_layer_norm.weight', 'transformer.layers.11.attention.post_layer_norm.weight', 'transformer.layers.1.attention.position_indices', 'transformer.layers.1.attention.out_proj.bias', 'transformer.layers.1.mlp.mlp.4.weight', 'transformer.layers.8.mlp.mlp.4.weight', 'transformer.layers.9.attention.position_indices', 'classifier.nonlinearity.5.bias', 'transformer.layers.3.attention.in_proj_v.bias', 'transformer.layers.6.attention.post_layer_norm.weight', 'transformer.layers.7.attention.position_indices', 'transformer.layers.2.attention.out_proj.bias', 'transformer.layers.10.attention.in_proj_v.weight', 'transformer.layers.2.attention.position_indices', 'transformer.layers.6.mlp.mlp.1.weight', 'transformer.layers.11.attention.in_proj_qk.weight', 'transformer.layers.9.attention.in_proj_v.weight', 'transformer.layers.1.attention.in_proj_qk.bias', 'transformer.layers.0.attention.post_layer_norm.bias', 'transformer.layers.9.prev_layer_weights', 'transformer.layers.5.attention.in_proj_v.bias', 'transformer.layers.3.attention.in_proj_v.weight', 'transformer.layers.2.attention.post_layer_norm.bias', 'transformer.layers.1.attention.in_proj_v.bias', 'transformer.layers.1.attention.out_proj.weight', 'transformer.layers.2.attention.post_layer_norm.weight', 'transformer.layers.9.attention.in_proj_qk.bias', 'transformer.layers.2.prev_layer_weights', 'transformer.layers.2.attention.in_proj_v.bias', 'transformer.layers.5.mlp.mlp.1.weight', 'transformer.layers.7.attention.in_proj_qk.bias', 'transformer.layers.10.attention.in_proj_qk.weight', 'transformer.layers.1.prev_layer_weights', 'transformer.layers.4.attention.in_proj_v.weight', 'classifier.nonlinearity.1.bias', 'transformer.layers.6.attention.in_proj_v.bias', 'transformer.layers.8.prev_layer_weights', 'transformer.layers.11.attention.out_proj.bias', 'transformer.layers.7.attention.post_layer_norm.weight', 'transformer.layers.6.prev_layer_weights', 'transformer.layers.0.prev_layer_weights', 'transformer.layers.6.attention.post_layer_norm.bias', 'transformer.layers.8.attention.out_proj.bias', 'transformer.layers.4.attention.out_proj.bias', 'transformer.layers.11.mlp.mlp.4.weight', 'transformer.layers.5.prev_layer_weights', 'transformer.layers.10.attention.in_proj_v.bias', 'transformer.layers.1.attention.in_proj_qk.weight', 'transformer.layers.8.attention.in_proj_qk.weight', 'transformer.layers.3.attention.out_proj.bias', 'transformer.layers.9.attention.in_proj_qk.weight', 'transformer.layers.5.attention.out_proj.bias', 'transformer.layers.0.attention.in_proj_v.bias', 'transformer.layers.5.attention.in_proj_qk.weight', 'transformer.layers.0.attention.position_indices', 'transformer.layers.2.attention.in_proj_qk.weight', 'transformer.layers.3.attention.out_proj.weight', 'transformer.layers.4.prev_layer_weights', 'transformer.layers.11.mlp.mlp.1.weight', 'classifier.nonlinearity.1.weight', 'embedding.relative_layer_norm.bias', 'transformer.layers.3.attention.in_proj_qk.bias', 'transformer.layers.9.attention.post_layer_norm.weight', 'transformer.layers.2.mlp.mlp.1.weight', 'transformer.layers.6.attention.in_proj_qk.weight', 'transformer.layers.7.mlp.mlp.1.weight', 'transformer.layers.6.attention.in_proj_v.weight', 'transformer.layers.3.mlp.mlp.1.weight', 'transformer.layers.5.attention.post_layer_norm.bias', 'transformer.layers.1.attention.post_layer_norm.bias', 'transformer.layers.0.attention.post_layer_norm.weight', 'transformer.layers.11.attention.post_layer_norm.bias', 'transformer.layers.1.attention.in_proj_v.weight', 'transformer.layers.5.mlp.mlp.4.weight', 'transformer.layers.7.attention.in_proj_qk.weight', 'transformer.layers.7.attention.out_proj.bias', 'transformer.layers.4.mlp.mlp.4.weight', 'transformer.layers.0.mlp.mlp.4.weight', 'transformer.layers.8.attention.position_indices', 'transformer.layers.2.mlp.mlp.4.weight', 'transformer.layers.6.attention.out_proj.bias', 'transformer.layers.0.attention.out_proj.weight', 'transformer.layers.4.attention.in_proj_qk.weight', 'transformer.layers.6.attention.in_proj_qk.bias', 'transformer.layers.3.attention.position_indices', 'transformer.layers.3.attention.post_layer_norm.weight', 'transformer.layers.8.attention.post_layer_norm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#@title Load model and evaluate (BLiMP) { display-mode: \"form\" }\n",
        "model = \"/content/elc-bert-replica\" #@param {\"type\": \"string\"}\n",
        "model_type = \"encoder\" #@param [\"decoder\", \"encoder\", \"encoder-decoder\"]\n",
        "# file_name = \"examples3.csv\" #@param {\"type\": \"string\"}\n",
        "# model_names = [\"opt-125m\", \"opt-350m\", \"opt-1.3b\", \"opt-2.7b\"] #@param {\"type\": \"raw\"}\n",
        "\n",
        "%cd /content/evaluation-pipeline-2023\n",
        "!python3.10 /content/evaluation-pipeline-2023/babylm_eval.py \\\n",
        "  \"$model\" \\\n",
        "  \"$model_type\" \\\n",
        "  -t \"blimp\" \\\n",
        "  --trust_remote_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKzgjovKEDTh",
        "outputId": "ba0da0be-54f2-408b-f387-bbe0b71d3e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/./collect_results.py\", line 71, in <module>\n",
            "    task_dicts[task] = make_task_dict(task, preds_path)\n",
            "  File \"/content/evaluation-pipeline-2023/./collect_results.py\", line 38, in make_task_dict\n",
            "    raise FileNotFoundError(f\"Warning: no predictions found for the \\\"{task_name}\\\" ({task_type}) task!\")\n",
            "FileNotFoundError: Warning: no predictions found for the \"cola\" (glue) task!\n"
          ]
        }
      ],
      "source": [
        "!python3.10 ./collect_results.py /content/evaluation-pipeline-2023/elc-bert-replica"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install evaluate\n"
      ],
      "metadata": {
        "id": "i64lw-sQH3I9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f812194c-48f6-4f5c-cfef-243ba8ddf402"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/elc-bert-replica/finetune"
      ],
      "metadata": {
        "id": "okAGI0YB0Fe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PorzVcsqTrbf",
        "outputId": "f5288ab0-a0aa-459f-bc4b-0927680ce395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/evaluation-pipeline-2023\n",
            "2025-05-21 17:19:36.040284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747847976.297918    3648 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747847976.363282    3648 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:19:36.883855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:19:54.086330: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747847994.106694    3777 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747847994.112940    3777 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:19:54.132263: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:20:05.045866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848005.066622    3838 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848005.072779    3838 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:20:05.092844: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:20:16.107683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848016.127869    3897 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848016.133845    3897 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:20:16.154289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:20:27.108609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848027.128981    3956 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848027.135037    3956 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:20:27.155244: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:20:37.941427: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848037.961532    4017 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848037.967616    4017 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:20:37.988299: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:20:49.972048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848049.992060    4080 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848049.998190    4080 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:20:50.017742: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:21:01.039219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848061.059428    4135 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848061.065594    4135 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:21:01.084937: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:21:12.009578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848072.029518    4198 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848072.035607    4198 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:21:12.055813: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:21:22.865754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848082.900574    4257 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848082.911421    4257 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:21:22.944576: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:21:33.631712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848093.663916    4318 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848093.673759    4318 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:21:33.704175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:21:44.940121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848104.960099    4382 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848104.966573    4382 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:21:44.986275: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:21:56.054520: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848116.073948    4441 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848116.079798    4441 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:21:56.099201: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:22:07.114170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848127.133963    4502 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848127.140021    4502 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:22:07.159880: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:22:18.180796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848138.201025    4561 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848138.207328    4561 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:22:18.227931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:22:29.093527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848149.115096    4620 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848149.121327    4620 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:22:29.141927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:22:40.023545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848160.044956    4677 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848160.051023    4677 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:22:40.071303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:22:51.108887: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848171.129546    4736 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848171.135496    4736 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:22:51.155423: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:23:02.215821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848182.236093    4795 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848182.242274    4795 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:23:02.262827: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:23:13.135116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848193.168399    4856 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848193.178280    4856 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:23:13.210394: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:23:23.685717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848203.719073    4915 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848203.727230    4915 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:23:23.757860: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n",
            "2025-05-21 17:23:34.649200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747848214.668416    4976 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747848214.674189    4976 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-21 17:23:34.693387: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 731, in <module>\n",
            "    main()\n",
            "  File \"/content/evaluation-pipeline-2023/finetune_classification.py\", line 241, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/hf_argparser.py\", line 367, in parse_args_into_dataclasses\n",
            "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
            "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--evaluation_strategy', 'steps']\n"
          ]
        }
      ],
      "source": [
        "#@title Load model and evaluate ((Super)GLUE) { display-mode: \"form\" }\n",
        "#@markdown Run this cell to fine-tune your model on (Super)GLUE tasks.\n",
        "#@markdown We provide some default hyperparameters that you may adjust.\n",
        "model = \"/content/elc-bert-replica\" #@param {\"type\": \"string\"}\n",
        "learning_rate = 5e-5 #@param {\"type\": \"number\"}\n",
        "batch_size = 64 #@param {\"type\": \"integer\"}\n",
        "eval_every = 200 #@param {\"type\": \"integer\"}\n",
        "patience = 10 #@param {\"type\": \"integer\"}\n",
        "max_epochs = 10 #@param {\"type\": \"integer\"}\n",
        "seed = 12 #@param {\"type\": \"integer\"}\n",
        "# file_name = \"examples3.csv\" #@param {\"type\": \"string\"}\n",
        "# model_names = [\"opt-125m\", \"opt-350m\", \"opt-1.3b\", \"opt-2.7b\"] #@param {\"type\": \"raw\"}\n",
        "\n",
        "%cd /content/evaluation-pipeline-2023\n",
        "!./finetune_all_tasks.sh \\\n",
        "    \"$model\" \\\n",
        "    \"$learning_rate\" \\\n",
        "    \"$patience\" \\\n",
        "    \"$batch_size\" \\\n",
        "    \"$eval_every\" \\\n",
        "    \"$max_epochs\" \\\n",
        "    \"$seed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQqPW7TiYJS",
        "outputId": "c5f6f1a0-37c9-47b9-ef04-49751ea08e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/evaluation-pipeline-2023\n"
          ]
        }
      ],
      "source": [
        "!cd /content\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "save_directory = \"./bert_model2\"\n",
        "\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory, safe_serialization=False)\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAf8AQi8IwPi",
        "outputId": "706a5a87-f48c-46e6-9013-8255d4515b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: urllib3>=1.25.10 in /usr/local/lib/python3.10/dist-packages (from responses<0.19->evaluate) (2.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "swkYEN28FaJl",
        "outputId": "1186b1a6-8acd-46ce-f102-f994d71ec462"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/zeroshot.zip'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Full paths to the folders you want to zip\n",
        "shutil.make_archive('/content/finetune', 'zip', '/content/evaluation-pipeline-2023/elc-bert-replica/finetune')\n",
        "shutil.make_archive('/content/zeroshot', 'zip', '/content/evaluation-pipeline-2023/elc-bert-replica/zeroshot')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Full paths to the folders you want to zip\n",
        "shutil.make_archive('/content/evaluation-pipeline-2023', 'zip', '/content/evaluation-pipeline-2023')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WzzqToZ8iGOO",
        "outputId": "113006e9-da86-4dc7-ea54-257a347ed58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/evaluation-pipeline-2023.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd /content/evaluation-pipeline-2023\n",
        "ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auwytR0foP-e",
        "outputId": "c186f945-b633-4268-be2a-3d8b3328866d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 81160\n",
            "drwxr-xr-x 2 root root     4096 May 11 18:28 aoa_data\n",
            "drwxr-xr-x 2 root root     4096 May 11 18:28 assets\n",
            "-rw-r--r-- 1 root root     4804 May 11 18:28 babylm_eval.py\n",
            "-rw-r--r-- 1 root root       34 May 11 18:28 CODEOWNERS\n",
            "-rw-r--r-- 1 root root     3713 May 11 18:28 collect_results.py\n",
            "drwxr-xr-x 3 root root     4096 May 11 18:28 docs\n",
            "drwxr-xr-x 7 root root     4096 May 11 18:28 filter-data\n",
            "-rw-r--r-- 1 root root 61762326 May 11 18:28 filter_data.zip\n",
            "-rwxrwxrwx 1 root root     1003 May 11 18:28 finetune_all_tasks.sh\n",
            "-rw-r--r-- 1 root root    32453 May 11 18:46 finetune_classification.py\n",
            "-rwxrwxrwx 1 root root     1255 May 11 18:28 finetune_model.sh\n",
            "-rw-r--r-- 1 root root       40 May 11 18:28 ignore.txt\n",
            "-rw-r--r-- 1 root root     1067 May 11 18:28 LICENSE.md\n",
            "drwxr-xr-x 7 root root     4096 May 11 18:28 lm_eval\n",
            "drwxr-xr-x 2 root root     4096 May 11 18:29 lm_eval.egg-info\n",
            "-rw-r--r-- 1 root root     7347 May 11 18:28 main.py\n",
            "-rw-r--r-- 1 root root    13536 May 11 18:28 README.md\n",
            "-rw-r--r-- 1 root root 21205894 May 11 18:28 sample_predictions.json\n",
            "drwxr-xr-x 2 root root     4096 May 11 18:28 scripts\n",
            "-rw-r--r-- 1 root root     2033 May 11 18:28 setup.py\n",
            "drwxr-xr-x 2 root root     4096 May 11 18:28 templates\n",
            "drwxr-xr-x 3 root root     4096 May 11 18:28 tests\n",
            "drwxr-xr-x 2 root root     4096 May 11 18:28 transformers_modified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 ./*.sh"
      ],
      "metadata": {
        "id": "KhzRoOdmpGVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/elc-bert-replica\", weights_only=False)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W73nRbLzD1j",
        "outputId": "fbeb746e-dea1-4edb-f0d0-15bd74d95c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for /content/elc-bert-replica contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co//content/elc-bert-replica.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LtgBertForSequenceClassification were not initialized from the model checkpoint at /content/elc-bert-replica and are newly initialized: ['embedding.relative_embedding', 'embedding.relative_layer_norm.bias', 'embedding.relative_layer_norm.weight', 'embedding.word_embedding.weight', 'transformer.layers.0.attention.in_proj_qk.bias', 'transformer.layers.0.attention.in_proj_qk.weight', 'transformer.layers.0.attention.in_proj_v.bias', 'transformer.layers.0.attention.in_proj_v.weight', 'transformer.layers.0.attention.out_proj.bias', 'transformer.layers.0.attention.out_proj.weight', 'transformer.layers.0.attention.position_indices', 'transformer.layers.0.attention.post_layer_norm.bias', 'transformer.layers.0.attention.post_layer_norm.weight', 'transformer.layers.0.mlp.mlp.1.weight', 'transformer.layers.0.mlp.mlp.4.weight', 'transformer.layers.0.prev_layer_weights', 'transformer.layers.1.attention.in_proj_qk.bias', 'transformer.layers.1.attention.in_proj_qk.weight', 'transformer.layers.1.attention.in_proj_v.bias', 'transformer.layers.1.attention.in_proj_v.weight', 'transformer.layers.1.attention.out_proj.bias', 'transformer.layers.1.attention.out_proj.weight', 'transformer.layers.1.attention.position_indices', 'transformer.layers.1.attention.post_layer_norm.bias', 'transformer.layers.1.attention.post_layer_norm.weight', 'transformer.layers.1.mlp.mlp.1.weight', 'transformer.layers.1.mlp.mlp.4.weight', 'transformer.layers.1.prev_layer_weights', 'transformer.layers.10.attention.in_proj_qk.bias', 'transformer.layers.10.attention.in_proj_qk.weight', 'transformer.layers.10.attention.in_proj_v.bias', 'transformer.layers.10.attention.in_proj_v.weight', 'transformer.layers.10.attention.out_proj.bias', 'transformer.layers.10.attention.out_proj.weight', 'transformer.layers.10.attention.position_indices', 'transformer.layers.10.attention.post_layer_norm.bias', 'transformer.layers.10.attention.post_layer_norm.weight', 'transformer.layers.10.mlp.mlp.1.weight', 'transformer.layers.10.mlp.mlp.4.weight', 'transformer.layers.10.prev_layer_weights', 'transformer.layers.11.attention.in_proj_qk.bias', 'transformer.layers.11.attention.in_proj_qk.weight', 'transformer.layers.11.attention.in_proj_v.bias', 'transformer.layers.11.attention.in_proj_v.weight', 'transformer.layers.11.attention.out_proj.bias', 'transformer.layers.11.attention.out_proj.weight', 'transformer.layers.11.attention.position_indices', 'transformer.layers.11.attention.post_layer_norm.bias', 'transformer.layers.11.attention.post_layer_norm.weight', 'transformer.layers.11.mlp.mlp.1.weight', 'transformer.layers.11.mlp.mlp.4.weight', 'transformer.layers.11.prev_layer_weights', 'transformer.layers.2.attention.in_proj_qk.bias', 'transformer.layers.2.attention.in_proj_qk.weight', 'transformer.layers.2.attention.in_proj_v.bias', 'transformer.layers.2.attention.in_proj_v.weight', 'transformer.layers.2.attention.out_proj.bias', 'transformer.layers.2.attention.out_proj.weight', 'transformer.layers.2.attention.position_indices', 'transformer.layers.2.attention.post_layer_norm.bias', 'transformer.layers.2.attention.post_layer_norm.weight', 'transformer.layers.2.mlp.mlp.1.weight', 'transformer.layers.2.mlp.mlp.4.weight', 'transformer.layers.2.prev_layer_weights', 'transformer.layers.3.attention.in_proj_qk.bias', 'transformer.layers.3.attention.in_proj_qk.weight', 'transformer.layers.3.attention.in_proj_v.bias', 'transformer.layers.3.attention.in_proj_v.weight', 'transformer.layers.3.attention.out_proj.bias', 'transformer.layers.3.attention.out_proj.weight', 'transformer.layers.3.attention.position_indices', 'transformer.layers.3.attention.post_layer_norm.bias', 'transformer.layers.3.attention.post_layer_norm.weight', 'transformer.layers.3.mlp.mlp.1.weight', 'transformer.layers.3.mlp.mlp.4.weight', 'transformer.layers.3.prev_layer_weights', 'transformer.layers.4.attention.in_proj_qk.bias', 'transformer.layers.4.attention.in_proj_qk.weight', 'transformer.layers.4.attention.in_proj_v.bias', 'transformer.layers.4.attention.in_proj_v.weight', 'transformer.layers.4.attention.out_proj.bias', 'transformer.layers.4.attention.out_proj.weight', 'transformer.layers.4.attention.position_indices', 'transformer.layers.4.attention.post_layer_norm.bias', 'transformer.layers.4.attention.post_layer_norm.weight', 'transformer.layers.4.mlp.mlp.1.weight', 'transformer.layers.4.mlp.mlp.4.weight', 'transformer.layers.4.prev_layer_weights', 'transformer.layers.5.attention.in_proj_qk.bias', 'transformer.layers.5.attention.in_proj_qk.weight', 'transformer.layers.5.attention.in_proj_v.bias', 'transformer.layers.5.attention.in_proj_v.weight', 'transformer.layers.5.attention.out_proj.bias', 'transformer.layers.5.attention.out_proj.weight', 'transformer.layers.5.attention.position_indices', 'transformer.layers.5.attention.post_layer_norm.bias', 'transformer.layers.5.attention.post_layer_norm.weight', 'transformer.layers.5.mlp.mlp.1.weight', 'transformer.layers.5.mlp.mlp.4.weight', 'transformer.layers.5.prev_layer_weights', 'transformer.layers.6.attention.in_proj_qk.bias', 'transformer.layers.6.attention.in_proj_qk.weight', 'transformer.layers.6.attention.in_proj_v.bias', 'transformer.layers.6.attention.in_proj_v.weight', 'transformer.layers.6.attention.out_proj.bias', 'transformer.layers.6.attention.out_proj.weight', 'transformer.layers.6.attention.position_indices', 'transformer.layers.6.attention.post_layer_norm.bias', 'transformer.layers.6.attention.post_layer_norm.weight', 'transformer.layers.6.mlp.mlp.1.weight', 'transformer.layers.6.mlp.mlp.4.weight', 'transformer.layers.6.prev_layer_weights', 'transformer.layers.7.attention.in_proj_qk.bias', 'transformer.layers.7.attention.in_proj_qk.weight', 'transformer.layers.7.attention.in_proj_v.bias', 'transformer.layers.7.attention.in_proj_v.weight', 'transformer.layers.7.attention.out_proj.bias', 'transformer.layers.7.attention.out_proj.weight', 'transformer.layers.7.attention.position_indices', 'transformer.layers.7.attention.post_layer_norm.bias', 'transformer.layers.7.attention.post_layer_norm.weight', 'transformer.layers.7.mlp.mlp.1.weight', 'transformer.layers.7.mlp.mlp.4.weight', 'transformer.layers.7.prev_layer_weights', 'transformer.layers.8.attention.in_proj_qk.bias', 'transformer.layers.8.attention.in_proj_qk.weight', 'transformer.layers.8.attention.in_proj_v.bias', 'transformer.layers.8.attention.in_proj_v.weight', 'transformer.layers.8.attention.out_proj.bias', 'transformer.layers.8.attention.out_proj.weight', 'transformer.layers.8.attention.position_indices', 'transformer.layers.8.attention.post_layer_norm.bias', 'transformer.layers.8.attention.post_layer_norm.weight', 'transformer.layers.8.mlp.mlp.1.weight', 'transformer.layers.8.mlp.mlp.4.weight', 'transformer.layers.8.prev_layer_weights', 'transformer.layers.9.attention.in_proj_qk.bias', 'transformer.layers.9.attention.in_proj_qk.weight', 'transformer.layers.9.attention.in_proj_v.bias', 'transformer.layers.9.attention.in_proj_v.weight', 'transformer.layers.9.attention.out_proj.bias', 'transformer.layers.9.attention.out_proj.weight', 'transformer.layers.9.attention.position_indices', 'transformer.layers.9.attention.post_layer_norm.bias', 'transformer.layers.9.attention.post_layer_norm.weight', 'transformer.layers.9.mlp.mlp.1.weight', 'transformer.layers.9.mlp.mlp.4.weight', 'transformer.layers.9.prev_layer_weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LtgBertForSequenceClassification(\n",
            "  (embedding): Embedding(\n",
            "    (word_embedding): Embedding(6144, 384)\n",
            "    (word_layer_norm): LayerNorm((384,), eps=1e-07, elementwise_affine=False)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (relative_layer_norm): LayerNorm((384,), eps=1e-07, elementwise_affine=True)\n",
            "  )\n",
            "  (transformer): Encoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-11): 12 x EncoderLayer(\n",
            "        (attention): Attention(\n",
            "          (in_proj_qk): Linear(in_features=384, out_features=768, bias=True)\n",
            "          (in_proj_v): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (out_proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (pre_layer_norm): LayerNorm((384,), eps=1e-07, elementwise_affine=False)\n",
            "          (post_layer_norm): LayerNorm((384,), eps=1e-07, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (mlp): FeedForward(\n",
            "          (mlp): Sequential(\n",
            "            (0): LayerNorm((384,), eps=1e-07, elementwise_affine=False)\n",
            "            (1): Linear(in_features=384, out_features=2048, bias=False)\n",
            "            (2): GeGLU()\n",
            "            (3): LayerNorm((1024,), eps=1e-07, elementwise_affine=False)\n",
            "            (4): Linear(in_features=1024, out_features=384, bias=False)\n",
            "            (5): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): Classifier(\n",
            "    (nonlinearity): Sequential(\n",
            "      (0): LayerNorm((384,), eps=1e-07, elementwise_affine=False)\n",
            "      (1): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (2): GELU(approximate='none')\n",
            "      (3): LayerNorm((384,), eps=1e-07, elementwise_affine=False)\n",
            "      (4): Dropout(p=0.2, inplace=False)\n",
            "      (5): Linear(in_features=384, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lh /content/elc-bert-replica"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmc9rukDzxzs",
        "outputId": "1f7e8fd6-dfb9-4958-c8fe-6157f125d5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 594M\n",
            "-rw-r--r--  1 root root  759 May 11 18:19 config.json\n",
            "-rw-r--r--  1 root root 5.5K May 11 18:19 configuration_ltgbert.py\n",
            "drwxr-xr-x 24 root root 4.0K May 11 18:44 \u001b[0m\u001b[01;34mfinetune\u001b[0m/\n",
            "-rw-r--r--  1 root root 297M May 11 18:19 model.bin\n",
            "-rw-r--r--  1 root root  35K May 11 18:19 modeling_ltgbert.py\n",
            "-rw-r--r--  1 root root 297M May 11 18:19 pytorch_model.bin\n",
            "-rw-r--r--  1 root root  173 May 11 18:19 special_tokens_map.json\n",
            "-rw-r--r--  1 root root  106 May 11 18:19 tokenizer_config.json\n",
            "-rw-r--r--  1 root root 132K May 11 18:19 tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.serialization import add_safe_globals\n",
        "from argparse import Namespace\n",
        "\n",
        "add_safe_globals([Namespace])\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"/content/elc-bert-replica\",\n",
        "    trust_remote_code=True,\n",
        "    ignore_mismatched_sizes=True,\n",
        "    weights_only=True,\n",
        ")\n",
        "\n",
        "print(\"\\n=== Parameter Device Check ===\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.device} | requires_grad={param.requires_grad}\")\n",
        "\n",
        "print(\"\\n=== Buffer Device Check ===\")\n",
        "for name, buffer in model.named_buffers():\n",
        "    print(f\"{name}: {buffer.device}\")\n",
        "\n",
        "print(\"\\nModel successfully loaded without meta tensors if no 'meta' devices are shown above.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rspr0FbX1ZW2",
        "outputId": "5027c94f-cf6f-45c7-ca95-d344a7295cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LtgBertForSequenceClassification were not initialized from the model checkpoint at /content/elc-bert-replica and are newly initialized: ['embedding.relative_embedding', 'embedding.relative_layer_norm.bias', 'embedding.relative_layer_norm.weight', 'embedding.word_embedding.weight', 'transformer.layers.0.attention.in_proj_qk.bias', 'transformer.layers.0.attention.in_proj_qk.weight', 'transformer.layers.0.attention.in_proj_v.bias', 'transformer.layers.0.attention.in_proj_v.weight', 'transformer.layers.0.attention.out_proj.bias', 'transformer.layers.0.attention.out_proj.weight', 'transformer.layers.0.attention.position_indices', 'transformer.layers.0.attention.post_layer_norm.bias', 'transformer.layers.0.attention.post_layer_norm.weight', 'transformer.layers.0.mlp.mlp.1.weight', 'transformer.layers.0.mlp.mlp.4.weight', 'transformer.layers.0.prev_layer_weights', 'transformer.layers.1.attention.in_proj_qk.bias', 'transformer.layers.1.attention.in_proj_qk.weight', 'transformer.layers.1.attention.in_proj_v.bias', 'transformer.layers.1.attention.in_proj_v.weight', 'transformer.layers.1.attention.out_proj.bias', 'transformer.layers.1.attention.out_proj.weight', 'transformer.layers.1.attention.position_indices', 'transformer.layers.1.attention.post_layer_norm.bias', 'transformer.layers.1.attention.post_layer_norm.weight', 'transformer.layers.1.mlp.mlp.1.weight', 'transformer.layers.1.mlp.mlp.4.weight', 'transformer.layers.1.prev_layer_weights', 'transformer.layers.10.attention.in_proj_qk.bias', 'transformer.layers.10.attention.in_proj_qk.weight', 'transformer.layers.10.attention.in_proj_v.bias', 'transformer.layers.10.attention.in_proj_v.weight', 'transformer.layers.10.attention.out_proj.bias', 'transformer.layers.10.attention.out_proj.weight', 'transformer.layers.10.attention.position_indices', 'transformer.layers.10.attention.post_layer_norm.bias', 'transformer.layers.10.attention.post_layer_norm.weight', 'transformer.layers.10.mlp.mlp.1.weight', 'transformer.layers.10.mlp.mlp.4.weight', 'transformer.layers.10.prev_layer_weights', 'transformer.layers.11.attention.in_proj_qk.bias', 'transformer.layers.11.attention.in_proj_qk.weight', 'transformer.layers.11.attention.in_proj_v.bias', 'transformer.layers.11.attention.in_proj_v.weight', 'transformer.layers.11.attention.out_proj.bias', 'transformer.layers.11.attention.out_proj.weight', 'transformer.layers.11.attention.position_indices', 'transformer.layers.11.attention.post_layer_norm.bias', 'transformer.layers.11.attention.post_layer_norm.weight', 'transformer.layers.11.mlp.mlp.1.weight', 'transformer.layers.11.mlp.mlp.4.weight', 'transformer.layers.11.prev_layer_weights', 'transformer.layers.2.attention.in_proj_qk.bias', 'transformer.layers.2.attention.in_proj_qk.weight', 'transformer.layers.2.attention.in_proj_v.bias', 'transformer.layers.2.attention.in_proj_v.weight', 'transformer.layers.2.attention.out_proj.bias', 'transformer.layers.2.attention.out_proj.weight', 'transformer.layers.2.attention.position_indices', 'transformer.layers.2.attention.post_layer_norm.bias', 'transformer.layers.2.attention.post_layer_norm.weight', 'transformer.layers.2.mlp.mlp.1.weight', 'transformer.layers.2.mlp.mlp.4.weight', 'transformer.layers.2.prev_layer_weights', 'transformer.layers.3.attention.in_proj_qk.bias', 'transformer.layers.3.attention.in_proj_qk.weight', 'transformer.layers.3.attention.in_proj_v.bias', 'transformer.layers.3.attention.in_proj_v.weight', 'transformer.layers.3.attention.out_proj.bias', 'transformer.layers.3.attention.out_proj.weight', 'transformer.layers.3.attention.position_indices', 'transformer.layers.3.attention.post_layer_norm.bias', 'transformer.layers.3.attention.post_layer_norm.weight', 'transformer.layers.3.mlp.mlp.1.weight', 'transformer.layers.3.mlp.mlp.4.weight', 'transformer.layers.3.prev_layer_weights', 'transformer.layers.4.attention.in_proj_qk.bias', 'transformer.layers.4.attention.in_proj_qk.weight', 'transformer.layers.4.attention.in_proj_v.bias', 'transformer.layers.4.attention.in_proj_v.weight', 'transformer.layers.4.attention.out_proj.bias', 'transformer.layers.4.attention.out_proj.weight', 'transformer.layers.4.attention.position_indices', 'transformer.layers.4.attention.post_layer_norm.bias', 'transformer.layers.4.attention.post_layer_norm.weight', 'transformer.layers.4.mlp.mlp.1.weight', 'transformer.layers.4.mlp.mlp.4.weight', 'transformer.layers.4.prev_layer_weights', 'transformer.layers.5.attention.in_proj_qk.bias', 'transformer.layers.5.attention.in_proj_qk.weight', 'transformer.layers.5.attention.in_proj_v.bias', 'transformer.layers.5.attention.in_proj_v.weight', 'transformer.layers.5.attention.out_proj.bias', 'transformer.layers.5.attention.out_proj.weight', 'transformer.layers.5.attention.position_indices', 'transformer.layers.5.attention.post_layer_norm.bias', 'transformer.layers.5.attention.post_layer_norm.weight', 'transformer.layers.5.mlp.mlp.1.weight', 'transformer.layers.5.mlp.mlp.4.weight', 'transformer.layers.5.prev_layer_weights', 'transformer.layers.6.attention.in_proj_qk.bias', 'transformer.layers.6.attention.in_proj_qk.weight', 'transformer.layers.6.attention.in_proj_v.bias', 'transformer.layers.6.attention.in_proj_v.weight', 'transformer.layers.6.attention.out_proj.bias', 'transformer.layers.6.attention.out_proj.weight', 'transformer.layers.6.attention.position_indices', 'transformer.layers.6.attention.post_layer_norm.bias', 'transformer.layers.6.attention.post_layer_norm.weight', 'transformer.layers.6.mlp.mlp.1.weight', 'transformer.layers.6.mlp.mlp.4.weight', 'transformer.layers.6.prev_layer_weights', 'transformer.layers.7.attention.in_proj_qk.bias', 'transformer.layers.7.attention.in_proj_qk.weight', 'transformer.layers.7.attention.in_proj_v.bias', 'transformer.layers.7.attention.in_proj_v.weight', 'transformer.layers.7.attention.out_proj.bias', 'transformer.layers.7.attention.out_proj.weight', 'transformer.layers.7.attention.position_indices', 'transformer.layers.7.attention.post_layer_norm.bias', 'transformer.layers.7.attention.post_layer_norm.weight', 'transformer.layers.7.mlp.mlp.1.weight', 'transformer.layers.7.mlp.mlp.4.weight', 'transformer.layers.7.prev_layer_weights', 'transformer.layers.8.attention.in_proj_qk.bias', 'transformer.layers.8.attention.in_proj_qk.weight', 'transformer.layers.8.attention.in_proj_v.bias', 'transformer.layers.8.attention.in_proj_v.weight', 'transformer.layers.8.attention.out_proj.bias', 'transformer.layers.8.attention.out_proj.weight', 'transformer.layers.8.attention.position_indices', 'transformer.layers.8.attention.post_layer_norm.bias', 'transformer.layers.8.attention.post_layer_norm.weight', 'transformer.layers.8.mlp.mlp.1.weight', 'transformer.layers.8.mlp.mlp.4.weight', 'transformer.layers.8.prev_layer_weights', 'transformer.layers.9.attention.in_proj_qk.bias', 'transformer.layers.9.attention.in_proj_qk.weight', 'transformer.layers.9.attention.in_proj_v.bias', 'transformer.layers.9.attention.in_proj_v.weight', 'transformer.layers.9.attention.out_proj.bias', 'transformer.layers.9.attention.out_proj.weight', 'transformer.layers.9.attention.position_indices', 'transformer.layers.9.attention.post_layer_norm.bias', 'transformer.layers.9.attention.post_layer_norm.weight', 'transformer.layers.9.mlp.mlp.1.weight', 'transformer.layers.9.mlp.mlp.4.weight', 'transformer.layers.9.prev_layer_weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Parameter Device Check ===\n",
            "embedding.relative_embedding: cpu | requires_grad=True\n",
            "embedding.word_embedding.weight: cpu | requires_grad=True\n",
            "embedding.relative_layer_norm.weight: cpu | requires_grad=True\n",
            "embedding.relative_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.0.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.0.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.0.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.0.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.1.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.1.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.1.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.1.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.2.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.2.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.2.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.2.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.3.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.3.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.3.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.3.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.4.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.4.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.4.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.4.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.5.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.5.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.5.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.5.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.6.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.6.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.6.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.6.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.7.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.7.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.7.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.7.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.8.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.8.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.8.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.8.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.9.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.9.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.9.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.9.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.10.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.10.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.10.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.10.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "transformer.layers.11.prev_layer_weights: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.in_proj_qk.weight: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.in_proj_qk.bias: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.in_proj_v.weight: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.in_proj_v.bias: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.out_proj.weight: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.out_proj.bias: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.post_layer_norm.weight: cpu | requires_grad=True\n",
            "transformer.layers.11.attention.post_layer_norm.bias: cpu | requires_grad=True\n",
            "transformer.layers.11.mlp.mlp.1.weight: cpu | requires_grad=True\n",
            "transformer.layers.11.mlp.mlp.4.weight: cpu | requires_grad=True\n",
            "head.nonlinearity.1.weight: meta | requires_grad=True\n",
            "head.nonlinearity.1.bias: meta | requires_grad=True\n",
            "head.nonlinearity.5.weight: meta | requires_grad=True\n",
            "head.nonlinearity.5.bias: meta | requires_grad=True\n",
            "\n",
            "=== Buffer Device Check ===\n",
            "transformer.layers.0.attention.position_indices: cpu\n",
            "transformer.layers.1.attention.position_indices: cpu\n",
            "transformer.layers.2.attention.position_indices: cpu\n",
            "transformer.layers.3.attention.position_indices: cpu\n",
            "transformer.layers.4.attention.position_indices: cpu\n",
            "transformer.layers.5.attention.position_indices: cpu\n",
            "transformer.layers.6.attention.position_indices: cpu\n",
            "transformer.layers.7.attention.position_indices: cpu\n",
            "transformer.layers.8.attention.position_indices: cpu\n",
            "transformer.layers.9.attention.position_indices: cpu\n",
            "transformer.layers.10.attention.position_indices: cpu\n",
            "transformer.layers.11.attention.position_indices: cpu\n",
            "\n",
            "Model successfully loaded without meta tensors if no 'meta' devices are shown above.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}